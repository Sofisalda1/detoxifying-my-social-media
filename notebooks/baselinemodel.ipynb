{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in /Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages (from nltk) (8.1.2)\n",
      "Requirement already satisfied: joblib in /Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages (from nltk) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/kw/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Initialization\n",
    "!pip install nltk\n",
    "import nltk \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from cleanup_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "INPUT_NAME='train_wikipedia'\n",
    "#INPUT_NAME='train_civil'\n",
    "\n",
    "df=pd.read_csv(\"../data/\"+INPUT_NAME+ \"_pre_clean.csv\")\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I am ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I am really not trying to edit war. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>More I cannot make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation Why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I am ...      0   \n",
       "2  000113f07ec002fd  Hey man, I am really not trying to edit war. I...      0   \n",
       "3  0001b41b1c6bb37e   More I cannot make any real suggestions on im...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of badwords\n",
    "toxic_words = ['bitch', 'fuck', 'shit', 'piss', 'dick', 'motherfucker', 'ass', \n",
    "'asshole', 'bastard', 'damn', 'cunt', 'faggot', 'slut', 'whore']\n",
    "# not in: 'meathead','douche-bag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u2022' in position 1195: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/baselinemodel.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/baselinemodel.ipynb#ch0000023?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m handle_nontext(df[\u001b[39m\"\u001b[39;49m\u001b[39mcomment_text\u001b[39;49m\u001b[39m\"\u001b[39;49m] )\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/notebooks/cleanup_functions.py:70\u001b[0m, in \u001b[0;36mhandle_nontext\u001b[0;34m(panda_column)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/notebooks/cleanup_functions.py?line=68'>69</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_nontext\u001b[39m(panda_column):\n\u001b[0;32m---> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/notebooks/cleanup_functions.py?line=69'>70</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m panda_column\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mencode(\u001b[39m\"\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4322'>4323</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4323'>4324</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4324'>4325</a>\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4327'>4328</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4328'>4329</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4329'>4330</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4330'>4331</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4331'>4332</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4430'>4431</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4431'>4432</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4432'>4433</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1077'>1078</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1078'>1079</a>\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1079'>1080</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1081'>1082</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1130'>1131</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1131'>1132</a>\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1132'>1133</a>\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1133'>1134</a>\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1134'>1135</a>\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1135'>1136</a>\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1136'>1137</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1137'>1138</a>\u001b[0m             values,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1138'>1139</a>\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1139'>1140</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1140'>1141</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1142'>1143</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1143'>1144</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1144'>1145</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1145'>1146</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/notebooks/cleanup_functions.py:70\u001b[0m, in \u001b[0;36mhandle_nontext.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/notebooks/cleanup_functions.py?line=68'>69</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_nontext\u001b[39m(panda_column):\n\u001b[0;32m---> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/notebooks/cleanup_functions.py?line=69'>70</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m panda_column\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mencode(\u001b[39m\"\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u2022' in position 1195: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "df[\"comment_text\"] = handle_nontext(df[\"comment_text\"] )# then bytes make it diffcult to deal with data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bwtter\n",
      "30581\n"
     ]
    }
   ],
   "source": [
    "# function to get word from index\n",
    "def get_term(dict, search_index):\n",
    "    return list(dict.keys())[list(dict.values()).index(search_index)]\n",
    "print(get_term(vect.vocabulary_, 36776))\n",
    "\n",
    "# get index\n",
    "def get_word_index(dict, word):\n",
    "    return dict[word]\n",
    "print(get_word_index(vect.vocabulary_, 'bitch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "# analyzer = TfidfVectorizer(min_df=15).build_analyzer()\n",
    "\n",
    "def lemmatize_word(doc):\n",
    "    return (WNlemma.lemmatize(t) for t in analyzer(doc))\n",
    "\n",
    "lemm_vectorizer = CountVectorizer(min_df=15, analyzer=lemmatize_word)\n",
    "#lemm_vectorizer = TfidfVectorizer(min_df=15, analyzer=lemmatize_word)\n",
    "\n",
    "# Transform X_train\n",
    "X_train_lemm_vectorized = lemm_vectorizer.fit_transform(df['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': 6524,\n",
       " 'why': 18661,\n",
       " 'the': 17009,\n",
       " 'edits': 5859,\n",
       " 'made': 10413,\n",
       " 'under': 17734,\n",
       " 'my': 11371,\n",
       " 'username': 18037,\n",
       " 'hardcore': 8015,\n",
       " 'metallica': 10858,\n",
       " 'fan': 6695,\n",
       " 'were': 18583,\n",
       " 'reverted': 14489,\n",
       " 'they': 17058,\n",
       " 'not': 11759,\n",
       " 'vandalism': 18112,\n",
       " 'just': 9604,\n",
       " 'closure': 3531,\n",
       " 'on': 12039,\n",
       " 'some': 15845,\n",
       " 'gas': 7450,\n",
       " 'after': 940,\n",
       " 'voted': 18362,\n",
       " 'at': 1723,\n",
       " 'new': 11584,\n",
       " 'york': 19019,\n",
       " 'doll': 5537,\n",
       " 'fac': 6612,\n",
       " 'and': 1259,\n",
       " 'please': 12887,\n",
       " 'do': 5501,\n",
       " 'remove': 14208,\n",
       " 'template': 16905,\n",
       " 'from': 7276,\n",
       " 'talk': 16767,\n",
       " 'page': 12340,\n",
       " 'since': 15547,\n",
       " 'am': 1161,\n",
       " 'retired': 14444,\n",
       " 'now': 11800,\n",
       " '89': 546,\n",
       " '205': 336,\n",
       " '38': 454,\n",
       " '27': 408,\n",
       " 'aww': 1890,\n",
       " 'he': 8102,\n",
       " 'match': 10658,\n",
       " 'this': 17079,\n",
       " 'background': 1929,\n",
       " 'colour': 3667,\n",
       " 'seemingly': 15149,\n",
       " 'stuck': 16353,\n",
       " 'with': 18809,\n",
       " 'thanks': 17000,\n",
       " '21': 343,\n",
       " '51': 489,\n",
       " 'january': 9421,\n",
       " '11': 31,\n",
       " '2016': 332,\n",
       " 'utc': 18056,\n",
       " 'hey': 8229,\n",
       " 'man': 10500,\n",
       " 'really': 13861,\n",
       " 'trying': 17534,\n",
       " 'to': 17216,\n",
       " 'edit': 5848,\n",
       " 'war': 18437,\n",
       " 'it': 9363,\n",
       " 'is': 9325,\n",
       " 'that': 17004,\n",
       " 'guy': 7903,\n",
       " 'constantly': 4041,\n",
       " 'removing': 14210,\n",
       " 'relevant': 14149,\n",
       " 'information': 8970,\n",
       " 'talking': 16775,\n",
       " 'me': 10714,\n",
       " 'through': 17118,\n",
       " 'instead': 9083,\n",
       " 'of': 11967,\n",
       " 'seems': 15150,\n",
       " 'care': 3002,\n",
       " 'more': 11207,\n",
       " 'about': 610,\n",
       " 'formatting': 7141,\n",
       " 'than': 16993,\n",
       " 'actual': 761,\n",
       " 'info': 8963,\n",
       " 'cannot': 2953,\n",
       " 'make': 10470,\n",
       " 'any': 1370,\n",
       " 'real': 13847,\n",
       " 'suggestion': 16475,\n",
       " 'improvement': 8763,\n",
       " 'wondered': 18841,\n",
       " 'if': 8612,\n",
       " 'section': 15130,\n",
       " 'statistic': 16178,\n",
       " 'should': 15423,\n",
       " 'be': 2100,\n",
       " 'later': 9907,\n",
       " 'or': 12111,\n",
       " 'subsection': 16409,\n",
       " 'type': 17607,\n",
       " 'accident': 669,\n",
       " 'think': 17071,\n",
       " 'reference': 14014,\n",
       " 'may': 10691,\n",
       " 'need': 11513,\n",
       " 'tidying': 17153,\n",
       " 'so': 15773,\n",
       " 'are': 1526,\n",
       " 'all': 1084,\n",
       " 'in': 8769,\n",
       " 'exact': 6398,\n",
       " 'same': 14883,\n",
       " 'format': 7137,\n",
       " 'ie': 8611,\n",
       " 'date': 4665,\n",
       " 'etc': 6312,\n",
       " 'can': 2929,\n",
       " 'no': 11689,\n",
       " 'one': 12041,\n",
       " 'else': 5984,\n",
       " 'doe': 5524,\n",
       " 'first': 6934,\n",
       " 'you': 19022,\n",
       " 'have': 8080,\n",
       " 'preference': 13149,\n",
       " 'for': 7092,\n",
       " 'style': 16372,\n",
       " 'want': 18433,\n",
       " 'yourself': 19031,\n",
       " 'let': 10047,\n",
       " 'know': 9778,\n",
       " 'there': 17042,\n",
       " 'appears': 1426,\n",
       " 'backlog': 1932,\n",
       " 'article': 1610,\n",
       " 'review': 14493,\n",
       " 'guess': 7867,\n",
       " 'delay': 4844,\n",
       " 'until': 17941,\n",
       " 'reviewer': 14495,\n",
       " 'turn': 17572,\n",
       " 'up': 17966,\n",
       " 'listed': 10179,\n",
       " 'form': 7133,\n",
       " 'eg': 5894,\n",
       " 'wikipedia': 18722,\n",
       " 'transport': 17409,\n",
       " 'sir': 15575,\n",
       " 'hero': 8210,\n",
       " 'chance': 3201,\n",
       " 'remember': 14190,\n",
       " 'what': 18601,\n",
       " 'congratulation': 3970,\n",
       " 'a': 566,\n",
       " 'well': 18573,\n",
       " 'use': 18022,\n",
       " 'tool': 17257,\n",
       " 'cocksucker': 3576,\n",
       " 'before': 2148,\n",
       " 'piss': 12808,\n",
       " 'around': 1578,\n",
       " 'work': 18864,\n",
       " 'your': 19028,\n",
       " 'matt': 10675,\n",
       " 'ha': 7911,\n",
       " 'been': 2144,\n",
       " 'again': 947,\n",
       " 'will': 18753,\n",
       " 'banned': 2008,\n",
       " 'sorry': 15880,\n",
       " 'word': 18858,\n",
       " 'nonsense': 11726,\n",
       " 'wa': 18382,\n",
       " 'offensive': 11978,\n",
       " 'anyway': 1379,\n",
       " 'intending': 9131,\n",
       " 'write': 18918,\n",
       " 'anything': 1377,\n",
       " 'wow': 18900,\n",
       " 'would': 18895,\n",
       " 'jump': 9586,\n",
       " 'merely': 10823,\n",
       " 'requesting': 14315,\n",
       " 'encyclopedic': 6083,\n",
       " 'school': 15027,\n",
       " 'selective': 15165,\n",
       " 'breeding': 2654,\n",
       " 'but': 2837,\n",
       " 'almost': 1124,\n",
       " 'stub': 16348,\n",
       " 'point': 12925,\n",
       " 'animal': 1291,\n",
       " 'which': 18622,\n",
       " 'short': 15408,\n",
       " 'messy': 10850,\n",
       " 'give': 7596,\n",
       " 'must': 11353,\n",
       " 'someone': 15849,\n",
       " 'expertise': 6513,\n",
       " 'eugenics': 6338,\n",
       " '93': 554,\n",
       " '161': 100,\n",
       " '107': 25,\n",
       " '169': 108,\n",
       " 'alignment': 1080,\n",
       " 'subject': 16394,\n",
       " 'contrary': 4131,\n",
       " 'those': 17091,\n",
       " 'fair': 6652,\n",
       " 'rationale': 13805,\n",
       " 'image': 8657,\n",
       " 'jpg': 9548,\n",
       " 'uploading': 17983,\n",
       " 'notice': 11772,\n",
       " 'specifies': 15973,\n",
       " 'being': 2176,\n",
       " 'used': 18024,\n",
       " 'constitutes': 4047,\n",
       " 'addition': 783,\n",
       " 'boilerplate': 2478,\n",
       " 'also': 1139,\n",
       " 'out': 12206,\n",
       " 'description': 5009,\n",
       " 'specific': 15968,\n",
       " 'using': 18046,\n",
       " 'each': 5779,\n",
       " 'consistent': 4021,\n",
       " 'go': 7643,\n",
       " 'include': 8812,\n",
       " 'uploaded': 17981,\n",
       " 'other': 12188,\n",
       " 'medium': 10761,\n",
       " 'consider': 4008,\n",
       " 'checking': 3275,\n",
       " 'specified': 15972,\n",
       " 'too': 17255,\n",
       " 'find': 6906,\n",
       " 'list': 10177,\n",
       " 'edited': 5851,\n",
       " 'by': 2857,\n",
       " 'clicking': 3497,\n",
       " 'contribution': 4146,\n",
       " 'link': 10160,\n",
       " 'located': 10240,\n",
       " 'very': 18222,\n",
       " 'top': 17263,\n",
       " 'when': 18610,\n",
       " 'logged': 10258,\n",
       " 'then': 17026,\n",
       " 'selecting': 15163,\n",
       " 'dropdown': 5680,\n",
       " 'box': 2587,\n",
       " 'note': 11766,\n",
       " '2006': 321,\n",
       " 'lacking': 9845,\n",
       " 'such': 16449,\n",
       " 'an': 1225,\n",
       " 'deleted': 4852,\n",
       " 'week': 18549,\n",
       " 'described': 5006,\n",
       " 'criterion': 4432,\n",
       " 'speedy': 15992,\n",
       " 'deletion': 4857,\n",
       " 'question': 13667,\n",
       " 'ask': 1641,\n",
       " 'them': 17020,\n",
       " 'copyright': 4224,\n",
       " 'thank': 16994,\n",
       " 'contribs': 4138,\n",
       " 'unspecified': 17928,\n",
       " 'source': 15896,\n",
       " 'noticed': 11777,\n",
       " 'file': 6876,\n",
       " 'currently': 4542,\n",
       " 'specify': 15974,\n",
       " 'who': 18647,\n",
       " 'created': 4387,\n",
       " 'content': 4095,\n",
       " 'status': 16186,\n",
       " 'unclear': 17703,\n",
       " 'did': 5156,\n",
       " 'create': 4386,\n",
       " 'owner': 12308,\n",
       " 'obtained': 11924,\n",
       " 'website': 18539,\n",
       " 'taken': 16757,\n",
       " 'together': 17229,\n",
       " 'restatement': 14399,\n",
       " 'term': 16939,\n",
       " 'usually': 18050,\n",
       " 'sufficient': 16466,\n",
       " 'however': 8456,\n",
       " 'holder': 8335,\n",
       " 'different': 5170,\n",
       " 'publisher': 13539,\n",
       " 'their': 17015,\n",
       " 'acknowledged': 725,\n",
       " 'adding': 782,\n",
       " 'add': 775,\n",
       " 'proper': 13410,\n",
       " 'licensing': 10093,\n",
       " 'tag': 16741,\n",
       " 'already': 1137,\n",
       " 'took': 17256,\n",
       " 'picture': 12762,\n",
       " 'audio': 1790,\n",
       " 'video': 18253,\n",
       " 'release': 14141,\n",
       " 'gfdl': 7560,\n",
       " 'believe': 2188,\n",
       " 'meet': 10763,\n",
       " 'see': 15140,\n",
       " 'full': 7318,\n",
       " 'tagged': 16742,\n",
       " 'following': 7067,\n",
       " 'unsourced': 17927,\n",
       " 'untagged': 17938,\n",
       " 'copyrighted': 4225,\n",
       " 'non': 11719,\n",
       " 'free': 7229,\n",
       " 'license': 10091,\n",
       " 'per': 12592,\n",
       " '48': 480,\n",
       " 'hour': 8442,\n",
       " 'discus': 5324,\n",
       " 'maybe': 10693,\n",
       " 'over': 12246,\n",
       " 'phone': 12726,\n",
       " 'exclusive': 6442,\n",
       " 'group': 7838,\n",
       " 'wp': 18901,\n",
       " 'taliban': 16766,\n",
       " 'good': 7680,\n",
       " 'destroying': 5048,\n",
       " 'self': 15168,\n",
       " 'appointed': 1446,\n",
       " 'purist': 13591,\n",
       " 'gang': 7427,\n",
       " 'asks': 1644,\n",
       " 'abt': 634,\n",
       " 'anti': 1350,\n",
       " 'social': 15781,\n",
       " 'destructive': 5051,\n",
       " 'clean': 3471,\n",
       " 'his': 8294,\n",
       " 'behavior': 2166,\n",
       " 'issue': 9358,\n",
       " 'nonsensical': 11727,\n",
       " 'warning': 18453,\n",
       " 'start': 16158,\n",
       " 'throwing': 17122,\n",
       " 'accusation': 708,\n",
       " 'itself': 9376,\n",
       " 'making': 10474,\n",
       " 'ad': 767,\n",
       " 'hominem': 8363,\n",
       " 'attack': 1751,\n",
       " 'going': 7661,\n",
       " 'strengthen': 16306,\n",
       " 'argument': 1542,\n",
       " 'look': 10279,\n",
       " 'like': 10123,\n",
       " 'abusing': 642,\n",
       " 'power': 13078,\n",
       " 'admin': 812,\n",
       " 'probably': 13292,\n",
       " 'single': 15561,\n",
       " 'most': 11237,\n",
       " 'talked': 16772,\n",
       " 'event': 6370,\n",
       " 'int': 9110,\n",
       " 'news': 11596,\n",
       " 'late': 9905,\n",
       " 'absence': 620,\n",
       " 'notable': 11761,\n",
       " 'only': 12048,\n",
       " 'living': 10212,\n",
       " 'ex': 6397,\n",
       " 'president': 13201,\n",
       " 'attend': 1760,\n",
       " 'certainly': 3164,\n",
       " 'carrier': 3032,\n",
       " 'intend': 9129,\n",
       " 'revert': 14488,\n",
       " 'hope': 8402,\n",
       " 'attracting': 1774,\n",
       " 'attention': 1767,\n",
       " 'willing': 18761,\n",
       " 'throw': 17120,\n",
       " 'quite': 13685,\n",
       " 'liberally': 10078,\n",
       " 'perhaps': 12611,\n",
       " 'achieve': 717,\n",
       " 'level': 10052,\n",
       " 'civility': 3424,\n",
       " 'where': 18612,\n",
       " 'we': 18513,\n",
       " 'rational': 13804,\n",
       " 'discussion': 5328,\n",
       " 'topic': 17264,\n",
       " 'resolve': 14365,\n",
       " 'matter': 10676,\n",
       " 'peacefully': 12538,\n",
       " 'oh': 12000,\n",
       " 'girl': 7591,\n",
       " 'above': 611,\n",
       " 'started': 16159,\n",
       " 'her': 8191,\n",
       " 'she': 15345,\n",
       " 'nose': 11755,\n",
       " 'belong': 2201,\n",
       " 'between': 2264,\n",
       " 'said': 14852,\n",
       " 'situation': 15587,\n",
       " 'settled': 15267,\n",
       " 'apologized': 1403,\n",
       " 'age': 950,\n",
       " '2002': 317,\n",
       " 'santana': 14917,\n",
       " '18': 127,\n",
       " 'year': 18992,\n",
       " 'old': 12016,\n",
       " 'came': 2917,\n",
       " 'february': 6788,\n",
       " '18th': 186,\n",
       " '19': 187,\n",
       " 'song': 15862,\n",
       " 'diplomat': 5223,\n",
       " 'third': 17075,\n",
       " 'signed': 15491,\n",
       " 'cam': 2914,\n",
       " 'label': 9834,\n",
       " 'roc': 14652,\n",
       " 'fella': 6807,\n",
       " '2003': 318,\n",
       " '20': 314,\n",
       " 'coming': 3705,\n",
       " 'own': 12306,\n",
       " 'town': 17317,\n",
       " 'down': 5607,\n",
       " 'yes': 19005,\n",
       " 'born': 2543,\n",
       " '1983': 288,\n",
       " 'how': 8452,\n",
       " 'could': 4295,\n",
       " 'older': 12017,\n",
       " 'lloyd': 10218,\n",
       " 'bank': 2002,\n",
       " '22': 355,\n",
       " 'birthday': 2341,\n",
       " 'passed': 12466,\n",
       " 'homie': 8362,\n",
       " '23': 366,\n",
       " 'death': 4707,\n",
       " 'god': 7652,\n",
       " 'forbid': 7094,\n",
       " 'thinking': 17073,\n",
       " 'equal': 6222,\n",
       " 'stop': 16271,\n",
       " 'changing': 3208,\n",
       " 'birth': 2339,\n",
       " 'bye': 2858,\n",
       " 'don': 5558,\n",
       " 'come': 3692,\n",
       " 'comming': 3727,\n",
       " 'back': 1926,\n",
       " 'tosser': 17289,\n",
       " 'redirect': 13978,\n",
       " 'pop': 12988,\n",
       " 'sense': 15204,\n",
       " 'argue': 1536,\n",
       " 'hindi': 8273,\n",
       " 'mean': 10719,\n",
       " 'bother': 2563,\n",
       " 'writing': 18922,\n",
       " 'something': 15853,\n",
       " 'regarding': 14072,\n",
       " 'posted': 13047,\n",
       " 'here': 8200,\n",
       " 'even': 6367,\n",
       " 'better': 2260,\n",
       " 'take': 16756,\n",
       " 'closer': 3527,\n",
       " 'premature': 13164,\n",
       " 'wrestling': 18914,\n",
       " 'men': 10796,\n",
       " 'surely': 16573,\n",
       " 'these': 17054,\n",
       " 'besides': 2246,\n",
       " 'recent': 13903,\n",
       " 'once': 12040,\n",
       " 'read': 13834,\n",
       " 'editing': 5852,\n",
       " 'film': 6885,\n",
       " 'simply': 15535,\n",
       " 'entirely': 6183,\n",
       " 'many': 10554,\n",
       " 'unnecessary': 17881,\n",
       " 'detail': 5057,\n",
       " 'bad': 1942,\n",
       " 'further': 7347,\n",
       " 'damage': 4610,\n",
       " '45': 475,\n",
       " 'yeah': 18991,\n",
       " 'studying': 16359,\n",
       " 'always': 1160,\n",
       " 'geometry': 7538,\n",
       " 'stated': 16168,\n",
       " 'six': 15589,\n",
       " 'arm': 1564,\n",
       " 'assertion': 1669,\n",
       " 'true': 17514,\n",
       " 'according': 691,\n",
       " 'kenneth': 9681,\n",
       " 'rather': 13800,\n",
       " 'irregular': 9310,\n",
       " 'crystal': 4494,\n",
       " 'far': 6712,\n",
       " 'common': 3740,\n",
       " 'variety': 18141,\n",
       " 'site': 15582,\n",
       " 'get': 7556,\n",
       " 'fact': 6626,\n",
       " 'off': 11969,\n",
       " 'because': 2126,\n",
       " 'still': 16245,\n",
       " 'decent': 4735,\n",
       " 'number': 11833,\n",
       " 'falsity': 6683,\n",
       " 'forgive': 7124,\n",
       " 'im': 8654,\n",
       " 'dont': 5570,\n",
       " 'signpost': 15500,\n",
       " '24': 378,\n",
       " 'september': 15234,\n",
       " '2012': 328,\n",
       " 'unsubscribe': 17930,\n",
       " 're': 13823,\n",
       " 'considering': 4014,\n",
       " '1st': 313,\n",
       " 'paragraph': 12396,\n",
       " 'understand': 17754,\n",
       " 'reason': 13872,\n",
       " 'sure': 16572,\n",
       " 'data': 4663,\n",
       " 'necessarily': 11507,\n",
       " 'wrong': 18925,\n",
       " 'persuaded': 12666,\n",
       " 'strategy': 16294,\n",
       " 'introducing': 9217,\n",
       " 'academic': 648,\n",
       " 'honor': 8382,\n",
       " 'unhelpful': 17819,\n",
       " 'approach': 1455,\n",
       " 'sitting': 15585,\n",
       " 'justice': 9605,\n",
       " 'similarly': 15520,\n",
       " 'enhanced': 6129,\n",
       " 'change': 3206,\n",
       " 'support': 16550,\n",
       " 'view': 18259,\n",
       " 'invite': 9255,\n",
       " 'anyone': 1375,\n",
       " 'visit': 18316,\n",
       " 'written': 18923,\n",
       " 'pair': 12352,\n",
       " 'jurist': 9601,\n",
       " 'a1': 567,\n",
       " 'benjamin': 2224,\n",
       " 'a2': 568,\n",
       " 'learned': 9969,\n",
       " 'hand': 7971,\n",
       " 'b1': 1908,\n",
       " 'john': 9505,\n",
       " 'marshall': 10613,\n",
       " 'harlan': 8024,\n",
       " 'b2': 1909,\n",
       " 'ii': 8626,\n",
       " 'becomes': 2133,\n",
       " 'current': 4541,\n",
       " 'version': 18218,\n",
       " 'either': 5915,\n",
       " 'improved': 8762,\n",
       " 'credential': 4399,\n",
       " 'introductory': 9219,\n",
       " 'help': 8170,\n",
       " 'repeat': 14247,\n",
       " 'sullivan': 16489,\n",
       " 'stanford': 16145,\n",
       " 'law': 9934,\n",
       " 'suggests': 16477,\n",
       " 'harvard': 8049,\n",
       " 'faculty': 6635,\n",
       " 'wonder': 18840,\n",
       " 'avoided': 1865,\n",
       " 'learning': 9971,\n",
       " 'others': 12189,\n",
       " 'managed': 10503,\n",
       " 'grasp': 7776,\n",
       " 'process': 13305,\n",
       " 'judging': 9566,\n",
       " 'anecdote': 1273,\n",
       " 'gently': 7521,\n",
       " 'illustrates': 8647,\n",
       " 'le': 9954,\n",
       " 'humorous': 8504,\n",
       " 'stronger': 16336,\n",
       " 'clarence': 3444,\n",
       " 'thomas': 17082,\n",
       " 'mention': 10802,\n",
       " 'wanting': 18435,\n",
       " 'return': 14461,\n",
       " 'degree': 4836,\n",
       " 'yale': 18978,\n",
       " 'minimum': 10971,\n",
       " 'questioning': 13670,\n",
       " 'deserves': 5015,\n",
       " 'reconsidered': 13938,\n",
       " 'radial': 13716,\n",
       " 'symmetry': 16688,\n",
       " 'several': 15277,\n",
       " 'extinct': 6578,\n",
       " 'lineage': 10146,\n",
       " 'included': 8813,\n",
       " 'apologize': 1402,\n",
       " 'knowledge': 9782,\n",
       " 'done': 5564,\n",
       " 'history': 8305,\n",
       " 'study': 16358,\n",
       " 'archaeology': 1508,\n",
       " 'scan': 14981,\n",
       " 'mail': 10446,\n",
       " 'translate': 17392,\n",
       " 'mother': 11241,\n",
       " 'child': 3312,\n",
       " 'case': 3049,\n",
       " 'against': 949,\n",
       " 'michael': 10888,\n",
       " 'jackson': 9395,\n",
       " 'studied': 16356,\n",
       " 'motif': 11245,\n",
       " 'reasoning': 13876,\n",
       " 'judged': 9563,\n",
       " 'upon': 17985,\n",
       " 'character': 3220,\n",
       " 'harshly': 8047,\n",
       " 'wacko': 18384,\n",
       " 'himself': 8271,\n",
       " 'tell': 16895,\n",
       " 'ignore': 8619,\n",
       " 'myself': 11378,\n",
       " 'continue': 4111,\n",
       " 'refuting': 14067,\n",
       " 'bullshit': 2793,\n",
       " 'jayjg': 9438,\n",
       " 'keep': 9669,\n",
       " '01': 4,\n",
       " '16': 96,\n",
       " 'jun': 9589,\n",
       " '2005': 320,\n",
       " 'ok': 12008,\n",
       " 'bit': 2348,\n",
       " 'example': 6411,\n",
       " 'base': 2052,\n",
       " 'duck': 5708,\n",
       " 'barnstar': 2035,\n",
       " 'life': 10104,\n",
       " 'u': 17622,\n",
       " 'star': 16148,\n",
       " 'post': 13045,\n",
       " 'block': 2407,\n",
       " 'expires': 6517,\n",
       " 'funny': 7342,\n",
       " 'thing': 17069,\n",
       " 'uncivil': 17699,\n",
       " 'heading': 8107,\n",
       " 'fight': 6868,\n",
       " 'freedom': 7231,\n",
       " 'contain': 4077,\n",
       " 'praise': 13100,\n",
       " 'looked': 10280,\n",
       " 'month': 11185,\n",
       " 'ago': 970,\n",
       " 'much': 11288,\n",
       " 'able': 600,\n",
       " 'quickly': 13677,\n",
       " 'had': 7923,\n",
       " 'text': 16981,\n",
       " 'hard': 8014,\n",
       " 'drive': 5670,\n",
       " 'meaning': 10721,\n",
       " 'updating': 17973,\n",
       " 'sound': 15890,\n",
       " 'time': 17170,\n",
       " 'generating': 7498,\n",
       " 'interest': 9153,\n",
       " 'spent': 16001,\n",
       " 'four': 7177,\n",
       " 'drum': 5689,\n",
       " 'freely': 7234,\n",
       " 'licensed': 10092,\n",
       " 'length': 10023,\n",
       " 'classical': 3458,\n",
       " 'music': 11345,\n",
       " 'unfortunately': 17810,\n",
       " 'attempt': 1757,\n",
       " 'failed': 6647,\n",
       " 'effectively': 5886,\n",
       " 'wikiproject': 18732,\n",
       " 'interested': 9154,\n",
       " 'wikipedia_talk': 18724,\n",
       " 'given': 7597,\n",
       " 'featured': 6785,\n",
       " 'digg': 5187,\n",
       " 'while': 18625,\n",
       " 'got': 7703,\n",
       " '1600': 98,\n",
       " 'imo': 8692,\n",
       " 'impressive': 8753,\n",
       " 'subpages': 16405,\n",
       " 'rfa': 14534,\n",
       " '2004': 319,\n",
       " 'difference': 5169,\n",
       " 'surprised': 16589,\n",
       " 'left': 9993,\n",
       " 'straw': 16296,\n",
       " 'never': 11581,\n",
       " 'claimed': 3437,\n",
       " 'position': 13033,\n",
       " 'practitioner': 13095,\n",
       " 'researcher': 14332,\n",
       " 'field': 6857,\n",
       " 'ignored': 8620,\n",
       " 'dsm': 5695,\n",
       " 'exactly': 6399,\n",
       " 'quote': 13691,\n",
       " 'say': 14972,\n",
       " 'agrees': 977,\n",
       " 'notion': 11784,\n",
       " 'absurd': 631,\n",
       " 'part': 12438,\n",
       " 'claim': 3435,\n",
       " 'pedophilia': 12558,\n",
       " 'sexual': 15286,\n",
       " 'orientation': 12154,\n",
       " 'hold': 8334,\n",
       " 'unfair': 17800,\n",
       " 'call': 2903,\n",
       " 'disorder': 5366,\n",
       " 'divided': 5478,\n",
       " 'end': 6087,\n",
       " 'day': 4681,\n",
       " 'value': 18100,\n",
       " 'judgment': 9567,\n",
       " 'cantor': 2961,\n",
       " 'pointed': 12926,\n",
       " 'earlier': 5788,\n",
       " 'thread': 17102,\n",
       " 'scientific': 15034,\n",
       " 'judgement': 9564,\n",
       " 'choose': 3344,\n",
       " 'clearly': 3484,\n",
       " 'pretend': 13220,\n",
       " 'basis': 2064,\n",
       " 'mainland': 10452,\n",
       " 'asia': 1636,\n",
       " 'includes': 8814,\n",
       " 'lower': 10325,\n",
       " 'basin': 2062,\n",
       " 'china': 3326,\n",
       " 'river': 14627,\n",
       " 'korea': 9798,\n",
       " 'fine': 6909,\n",
       " 'found': 7170,\n",
       " 'citation': 3411,\n",
       " 'comprehensive': 3836,\n",
       " 'dna': 5498,\n",
       " 'hammer': 7964,\n",
       " 'below': 2206,\n",
       " 'our': 12203,\n",
       " 'speculation': 15986,\n",
       " 'culture': 4519,\n",
       " 'brought': 2724,\n",
       " 'japan': 9423,\n",
       " 'migrant': 10912,\n",
       " 'trace': 17326,\n",
       " 'root': 14702,\n",
       " 'southeast': 15901,\n",
       " 'south': 15899,\n",
       " 'describes': 5007,\n",
       " 'migration': 10915,\n",
       " 'based': 2054,\n",
       " 'sry': 16098,\n",
       " 'gene': 7484,\n",
       " 'close': 3523,\n",
       " 'entire': 6182,\n",
       " 'haplogroup': 7996,\n",
       " 'proposed': 13422,\n",
       " 'asian': 1637,\n",
       " 'origin': 12156,\n",
       " 'definition': 4822,\n",
       " 'southern': 15903,\n",
       " 'dispersal': 5375,\n",
       " 'farmer': 6720,\n",
       " 'eventually': 6372,\n",
       " 'concluding': 3889,\n",
       " 'state': 16167,\n",
       " 'propose': 13421,\n",
       " 'chromosome': 3369,\n",
       " 'descend': 4999,\n",
       " 'prehistoric': 13156,\n",
       " 'southeastern': 15902,\n",
       " 'agriculture': 980,\n",
       " 'region': 14078,\n",
       " 'global': 7618,\n",
       " 'sample': 14888,\n",
       " 'consisted': 4019,\n",
       " '500': 486,\n",
       " 'male': 10481,\n",
       " '39': 456,\n",
       " 'population': 13000,\n",
       " 'including': 8815,\n",
       " 'sampled': 14889,\n",
       " 'across': 745,\n",
       " 'japanese': 9424,\n",
       " 'archipelago': 1514,\n",
       " 'pretty': 13228,\n",
       " 'everyone': 6380,\n",
       " 'warren': 18460,\n",
       " 'county': 4321,\n",
       " 'surrounding': 16598,\n",
       " 'glen': 7613,\n",
       " 'fall': 6670,\n",
       " 'hospital': 8428,\n",
       " 'qualifies': 13643,\n",
       " 'native': 11460,\n",
       " 'rachel': 13707,\n",
       " 'ray': 13816,\n",
       " 'actually': 763,\n",
       " 'lake': 9855,\n",
       " 'preceding': 13122,\n",
       " 'unsigned': 17924,\n",
       " 'comment': 3718,\n",
       " 'added': 776,\n",
       " '70': 519,\n",
       " '100': 16,\n",
       " '229': 364,\n",
       " '154': 89,\n",
       " '04': 7,\n",
       " '28': 414,\n",
       " '57': 498,\n",
       " 'august': 1795,\n",
       " '2007': 322,\n",
       " 'hi': 8234,\n",
       " 'explicit': 6527,\n",
       " 'fenian': 6820,\n",
       " 'warring': 18461,\n",
       " 'giant': 7569,\n",
       " 'terrorism': 16960,\n",
       " 'notability': 11760,\n",
       " 'placed': 12831,\n",
       " 'speedily': 15991,\n",
       " 'person': 12654,\n",
       " 'people': 12590,\n",
       " 'band': 1989,\n",
       " 'club': 3537,\n",
       " 'company': 3764,\n",
       " 'web': 18532,\n",
       " 'indicate': 8875,\n",
       " 'assert': 1666,\n",
       " 'guideline': 7877,\n",
       " 'generally': 7494,\n",
       " 'accepted': 659,\n",
       " 'contest': 4098,\n",
       " 'tagging': 16743,\n",
       " 'existing': 6480,\n",
       " 'db': 4685,\n",
       " 'leave': 9978,\n",
       " 'explaining': 6522,\n",
       " 'hesitate': 8222,\n",
       " 'confirm': 3939,\n",
       " 'check': 3272,\n",
       " 'biography': 2328,\n",
       " 'feel': 6801,\n",
       " 'lead': 9956,\n",
       " 'briefly': 2675,\n",
       " 'summarize': 16499,\n",
       " 'armenia': 1568,\n",
       " 'necessary': 11508,\n",
       " 'sentence': 15214,\n",
       " 'redundant': 13998,\n",
       " 'welcome': 18568,\n",
       " 'tfd': 16987,\n",
       " 'responded': 14384,\n",
       " 'without': 18816,\n",
       " 'seeing': 15142,\n",
       " 'response': 14389,\n",
       " 'yours': 19030,\n",
       " 'saw': 14968,\n",
       " 'mine': 10960,\n",
       " 'chicago': 3306,\n",
       " 'gay': 7464,\n",
       " 'white': 18637,\n",
       " 'tiger': 17158,\n",
       " 'meow': 10810,\n",
       " 'uh': 17644,\n",
       " 'two': 17602,\n",
       " 'way': 18506,\n",
       " 'erased': 6241,\n",
       " 'ww2': 18943,\n",
       " 'holocaust': 8348,\n",
       " 'brutally': 2740,\n",
       " 'jew': 9478,\n",
       " 'gypsy': 7908,\n",
       " 'slav': 15655,\n",
       " 'shave': 15341,\n",
       " 'head': 8103,\n",
       " 'bald': 1971,\n",
       " 'skinhead': 15618,\n",
       " 'meeting': 10764,\n",
       " 'doubt': 5593,\n",
       " 'bible': 2282,\n",
       " 'homosexuality': 8372,\n",
       " 'deadly': 4696,\n",
       " 'sin': 15543,\n",
       " 'forehead': 7107,\n",
       " 'mass': 10640,\n",
       " 'pal': 12360,\n",
       " 'last': 9900,\n",
       " 'fucking': 7304,\n",
       " 'appreciate': 1449,\n",
       " 'nazi': 11482,\n",
       " 'wish': 18801,\n",
       " 'anymore': 1374,\n",
       " 'beware': 2267,\n",
       " 'dark': 4648,\n",
       " 'side': 15469,\n",
       " 'fuck': 7297,\n",
       " 'filthy': 6894,\n",
       " 'as': 1626,\n",
       " 'dry': 5694,\n",
       " 'screwed': 15075,\n",
       " 'having': 8083,\n",
       " 'dominance': 5548,\n",
       " 'bow': 2580,\n",
       " 'almighty': 1123,\n",
       " 'administrator': 818,\n",
       " 'play': 12870,\n",
       " 'outside': 12238,\n",
       " 'mom': 11137,\n",
       " '76': 528,\n",
       " '122': 48,\n",
       " '79': 532,\n",
       " '82': 538,\n",
       " 'criticism': 4439,\n",
       " 'present': 13190,\n",
       " 'conforms': 3955,\n",
       " 'npv': 11808,\n",
       " 'rule': 14777,\n",
       " 'neutral': 11573,\n",
       " 'begin': 2155,\n",
       " 'offer': 11979,\n",
       " 'concerned': 3879,\n",
       " 'result': 14418,\n",
       " 'shock': 15396,\n",
       " 'complainant': 3797,\n",
       " 'into': 9200,\n",
       " 'lie': 10098,\n",
       " 'uncovered': 17720,\n",
       " 'perfectly': 12604,\n",
       " 'valid': 18090,\n",
       " 'telling': 16897,\n",
       " 'truth': 17528,\n",
       " 'machine': 10399,\n",
       " 'investigator': 9249,\n",
       " 'research': 14330,\n",
       " 'followup': 7069,\n",
       " 'story': 16279,\n",
       " 'possible': 13043,\n",
       " 'verify': 18207,\n",
       " 'false': 6676,\n",
       " 'matched': 10659,\n",
       " 'accused': 711,\n",
       " 'happened': 8000,\n",
       " 'arguing': 1541,\n",
       " 'respected': 14376,\n",
       " 'phd': 12708,\n",
       " 'baseless': 2055,\n",
       " 'agree': 972,\n",
       " 'though': 17093,\n",
       " 'appropriate': 1459,\n",
       " 'significance': 15493,\n",
       " 'lazy': 9949,\n",
       " 'stalking': 16129,\n",
       " 'absolute': 622,\n",
       " 'rubbish': 14761,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223542, 19210)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemm_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get index in df with specific word\n",
    "X_array = X_train_lemm_vectorized.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223542, 19210)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>001</th>\n",
       "      <th>004</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223537</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223540</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223542 rows  19210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00  001  004  007   01   02   03   04   05   06  ...          \\\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "223537  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "223538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "223539  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "223540  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "223541  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "\n",
       "                            \n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "223537  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "223538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "223539  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "223540  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "223541  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[223542 rows x 19210 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose X_array\n",
    "df_occurrence = pd.DataFrame(data=X_array,columns = lemm_vectorizer.get_feature_names_out())\n",
    "df_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '001', '004', ..., '', '', ''], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_corpus = lemm_vectorizer.get_feature_names_out()\n",
    "words_in_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if toxic words are in \n",
    "[curse_word in words_in_corpus for curse_word in toxic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.000000\n",
       "1         0.000000\n",
       "2         0.000000\n",
       "3         0.000000\n",
       "4         0.000000\n",
       "            ...   \n",
       "223537    0.000000\n",
       "223538    0.000000\n",
       "223539    0.000000\n",
       "223540    0.248969\n",
       "223541    0.000000\n",
       "Name: bitch, Length: 223542, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occurrence['bitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bitch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bitch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/baselinemodel.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/baselinemodel.ipynb#ch0000017?line=0'>1</a>\u001b[0m \u001b[39msum\u001b[39;49m(df[insult] \u001b[39mfor\u001b[39;49;00m insult \u001b[39min\u001b[39;49;00m toxic_words)\n",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/baselinemodel.ipynb Cell 21'\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/baselinemodel.ipynb#ch0000017?line=0'>1</a>\u001b[0m \u001b[39msum\u001b[39m(df[insult] \u001b[39mfor\u001b[39;00m insult \u001b[39min\u001b[39;00m toxic_words)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bitch'"
     ]
    }
   ],
   "source": [
    "sum(df[insult] for insult in toxic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad347432433d227a6a1af674451af37b20c66c076ff8f20805b46e8b7d486412"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
