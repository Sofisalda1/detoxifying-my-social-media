{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#!pip install twokenize\n",
    "#import twokenize\n",
    "#!pip install demoji\n",
    "import demoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223544</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>:Jerome, I see you never got around to this‚Ä¶! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223545</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223546</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223547</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223548</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "223544  fff8f64043129fa2  :Jerome, I see you never got around to this‚Ä¶! ...   \n",
       "223545  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n",
       "223546  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n",
       "223547  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n",
       "223548  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "223544      0             0        0       0       0              0  \n",
       "223545      0             0        0       0       0              0  \n",
       "223546      0             0        0       0       0              0  \n",
       "223547      1             0        1       0       1              0  \n",
       "223548      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikipedia=pd.read_csv(\"../data/train_wikipedia.csv\")\n",
    "#df2 = {'id': 31234234, 'comment_text': 'I love Pizza üçï! Shall we book a cab üöï to gizza?', 'toxic':0,\n",
    "#'severe_toxic':0,'obscene':1,'threat':1,'insult':1,'identity_hate':1}\n",
    "#df_wikipedia = df_wikipedia.append(df2, ignore_index = True)\n",
    "df_wikipedia.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove double quotations \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\\nMore\\nI can't make any real suggestions on i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \\nMore\\nI can't make any real suggestions on i...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_doublequotation(panda_text_column):\n",
    "    return panda_text_column.apply(lambda x: x.replace('\"', ''))\n",
    "df_wikipedia['comment_text'] = remove_doublequotation(df_wikipedia['comment_text'])\n",
    "df_wikipedia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling apostrophes (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apostrophes_expansion = {\n",
    "\"i'm\": \"i am\",\"I'm\": \"I am\", \"I'M\": \"I AM\", \n",
    "\"i'd\": \"i would\", \"I'd\": \"I would\",\"I'D\": \"I WOULD\",\n",
    "\"you're\": \"you are\", \"You're\": \"You are\", \"YOU'RE\": \"YOU ARE\",\n",
    "\"he's\": \"he is\",\"He's\": \"He is\",\"HE'S\": \"HE IS\",\n",
    "\"she's\": \"she is\",\"She's\": \"She is\",\"SHE'S\": \"SHE IS\",\n",
    "\"it's\":\"it is\", \"It's\":\"It is\", \"IT'S\":\"IT IS\",\n",
    "\"that's\": \"that is\", \"That's\": \"That is\",\"THAT'S\": \"THAT IS\",\n",
    "\"they're\": \"they are\",\"They're\": \"They are\",\"THEY'RE\": \"THEY ARE\",\n",
    "\"we're\": \"we are\",\"We're\": \"We are\",\"WE'RE\": \"WE ARE\",\n",
    "\"i've\": \"i have\", \"I've\": \"I have\", \"I'VE\": \"I HAVE\",\n",
    "\"you've\": \"you have\",\"You've\": \"You have\",\"YOU'VE\": \"YOU HAVE\",\n",
    "\"we've\": \"we have\",\"We've\": \"We have\",\"WE'VE\": \"WE HAVE\",\n",
    "\"ain't\": \"are not\",\"Ain't\": \"Are not\",\"AIN'T\": \"ARE NOT\",\n",
    "\"aren't\": \"are not\", \"Aren't\": \"Are not\",\"AREN'T\": \"ARE NOT\",\n",
    "\"isn't\": \"is not\", \"Isn't\": \"Is not\", \"ISN'T\": \"IS NOT\",\n",
    "\"don't\": \"do not\", \"Don't\": \"Do not\",\"DON'T\": \"DO NOT\",\n",
    "\"doesn't\": \"does not\", \"Doesn't\": \"Does not\", \"DOESN'T\": \"DOES NOT\",\n",
    "\"won't\": \"will not\",\"Won't\": \"Will not\", \"WON'T\": \"WILL NOT\",\n",
    "\"can't\": \"cannot\",\"Can't\": \"Cannot\", \"CAN'T\": \"CANNOT\",\n",
    "\"shouldn't\": \"should not\",\"Shouldn't\": \"Should not\",\"SHOULDN'T\": \"SHOULD NOT\",\n",
    "\"wouldn't\": \"would not\", \"Wouldn't\": \"Would not\", \"WOULDN'T\": \"WOULD NOT\",\n",
    "\"didn't\": \"did not\", \"Didn't\": \"Did not\", \"DIDN'T\": \"DID NOT\",\n",
    "\"weren't\":\"were not\",\"Weren't\":\"Were not\", \"WEREN'T\":\"WERE NOT\", \n",
    "\"wasn't\":\"was not\",\"Wasn't\":\"Was not\", \"WASN'T\":\"WAS NOT\", \n",
    "\"there's\": \"there is\", \"There's\": \"There is\", \"THERE'S\": \"THERE IS\",\n",
    "\"here's\": \"here is\", \"Here's\": \"Here is\", \"HERE'S\": \"HERE IS\",\n",
    "\"let's\": 'let us', \"Let's\": \"Let us\", \"LET'S\": \"LET US\"\n",
    "} \n",
    "\n",
    "def interpolate_apostrophes_string(string):\n",
    "    x = string.split(' ')\n",
    "    return \" \".join([Apostrophes_expansion[word] if word in Apostrophes_expansion else word for word in x])\n",
    "def interpolate_apostrophes_column(panda_text_column):\n",
    "    return panda_text_column.apply(lambda x: interpolate_apostrophes_string(x))\n",
    "    \n",
    "df_wikipedia['comment_text'] = interpolate_apostrophes_column(df_wikipedia.comment_text)\n",
    "df_wikipedia.to_csv('../data/test_apostrophes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonstandard spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=2'>3</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtextblob\u001b[39;00m \u001b[39mimport\u001b[39;00m TextBlob\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m panda_text_column\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: TextBlob(x)\u001b[39m.\u001b[39mcorrect())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=5'>6</a>\u001b[0m df_wikipedia[\u001b[39m'\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m correct_spelling(df_wikipedia[\u001b[39m'\u001b[39;49m\u001b[39mcomment_text\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb Cell 10'\u001b[0m in \u001b[0;36mcorrect_spelling\u001b[0;34m(panda_text_column)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrect_spelling\u001b[39m(panda_text_column):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=2'>3</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtextblob\u001b[39;00m \u001b[39mimport\u001b[39;00m TextBlob\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m panda_text_column\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: TextBlob(x)\u001b[39m.\u001b[39;49mcorrect())\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4322'>4323</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4323'>4324</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4324'>4325</a>\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4327'>4328</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4328'>4329</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4329'>4330</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4330'>4331</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4331'>4332</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4430'>4431</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4431'>4432</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/series.py?line=4432'>4433</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1077'>1078</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1078'>1079</a>\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1079'>1080</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1081'>1082</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1130'>1131</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1131'>1132</a>\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1132'>1133</a>\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1133'>1134</a>\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1134'>1135</a>\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1135'>1136</a>\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1136'>1137</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1137'>1138</a>\u001b[0m             values,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1138'>1139</a>\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1139'>1140</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1140'>1141</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1142'>1143</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1143'>1144</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1144'>1145</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/pandas/core/apply.py?line=1145'>1146</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb Cell 10'\u001b[0m in \u001b[0;36mcorrect_spelling.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrect_spelling\u001b[39m(panda_text_column):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=2'>3</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtextblob\u001b[39;00m \u001b[39mimport\u001b[39;00m TextBlob\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000009?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m panda_text_column\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: TextBlob(x)\u001b[39m.\u001b[39;49mcorrect())\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py:609\u001b[0m, in \u001b[0;36mBaseBlob.correct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=606'>607</a>\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mregexp_tokenize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=607'>608</a>\u001b[0m corrected \u001b[39m=\u001b[39m (Word(w)\u001b[39m.\u001b[39mcorrect() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens)\n\u001b[0;32m--> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=608'>609</a>\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(corrected)\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=609'>610</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(ret)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py:608\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=605'>606</a>\u001b[0m \u001b[39m# regex matches: word or punctuation or whitespace\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=606'>607</a>\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mtokenize\u001b[39m.\u001b[39mregexp_tokenize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=607'>608</a>\u001b[0m corrected \u001b[39m=\u001b[39m (Word(w)\u001b[39m.\u001b[39;49mcorrect() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m tokens)\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=608'>609</a>\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(corrected)\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=609'>610</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(ret)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py:142\u001b[0m, in \u001b[0;36mWord.correct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=135'>136</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcorrect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=136'>137</a>\u001b[0m     \u001b[39m'''Correct the spelling of the word. Returns the word with the highest\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=137'>138</a>\u001b[0m \u001b[39m    confidence using the spelling corrector.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=138'>139</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=139'>140</a>\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=140'>141</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Word(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspellcheck()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py:134\u001b[0m, in \u001b[0;36mWord.spellcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=124'>125</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspellcheck\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=125'>126</a>\u001b[0m     \u001b[39m'''Return a list of (word, confidence) tuples of spelling corrections.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=126'>127</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=127'>128</a>\u001b[0m \u001b[39m    Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=131'>132</a>\u001b[0m \u001b[39m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=132'>133</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/blob.py?line=133'>134</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m suggest(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstring)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/en/__init__.py:123\u001b[0m, in \u001b[0;36msuggest\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/en/__init__.py?line=119'>120</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuggest\u001b[39m(w):\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/en/__init__.py?line=120'>121</a>\u001b[0m     \u001b[39m\"\"\" Returns a list of (word, confidence)-tuples of spelling corrections.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/en/__init__.py?line=121'>122</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/en/__init__.py?line=122'>123</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m spelling\u001b[39m.\u001b[39;49msuggest(w)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py:1399\u001b[0m, in \u001b[0;36mSpelling.suggest\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1394'>1395</a>\u001b[0m \u001b[39mif\u001b[39;00m w\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39misdigit():\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1395'>1396</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(w, \u001b[39m1.0\u001b[39m)] \u001b[39m# 1.5\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1396'>1397</a>\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known([w]) \\\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1397'>1398</a>\u001b[0m           \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w)) \\\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1398'>1399</a>\u001b[0m           \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edit2(w)) \\\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1399'>1400</a>\u001b[0m           \u001b[39mor\u001b[39;00m [w]\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1400'>1401</a>\u001b[0m candidates \u001b[39m=\u001b[39m [(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(c, \u001b[39m0.0\u001b[39m), c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m candidates]\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1401'>1402</a>\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39msum\u001b[39m(p \u001b[39mfor\u001b[39;00m p, word \u001b[39min\u001b[39;00m candidates) \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py:1376\u001b[0m, in \u001b[0;36mSpelling._edit2\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1371'>1372</a>\u001b[0m \u001b[39m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1372'>1373</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1373'>1374</a>\u001b[0m \u001b[39m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1374'>1375</a>\u001b[0m \u001b[39m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1375'>1376</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39;49m(e2 \u001b[39mfor\u001b[39;49;00m e1 \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edit1(w) \u001b[39mfor\u001b[39;49;00m e2 \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edit1(e1) \u001b[39mif\u001b[39;49;00m e2 \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py:1376\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1371'>1372</a>\u001b[0m \u001b[39m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1372'>1373</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1373'>1374</a>\u001b[0m \u001b[39m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1374'>1375</a>\u001b[0m \u001b[39m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1375'>1376</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(e2 \u001b[39mfor\u001b[39;00m e1 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edit1(w) \u001b[39mfor\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edit1(e1) \u001b[39mif\u001b[39;00m e2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py:1366\u001b[0m, in \u001b[0;36mSpelling._edit1\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1359'>1360</a>\u001b[0m \u001b[39m# Of all spelling errors, 80% is covered by edit distance 1.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1360'>1361</a>\u001b[0m \u001b[39m# Edit distance 1 = one character deleted, swapped, replaced or inserted.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1361'>1362</a>\u001b[0m split \u001b[39m=\u001b[39m [(w[:i], w[i:]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(w) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1362'>1363</a>\u001b[0m delete, transpose, replace, insert \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1363'>1364</a>\u001b[0m     [a \u001b[39m+\u001b[39m b[\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mif\u001b[39;00m b],\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1364'>1365</a>\u001b[0m     [a \u001b[39m+\u001b[39m b[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m b[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m b[\u001b[39m2\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(b) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m],\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1365'>1366</a>\u001b[0m     [a \u001b[39m+\u001b[39m c \u001b[39m+\u001b[39m b[\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m Spelling\u001b[39m.\u001b[39mALPHA \u001b[39mif\u001b[39;00m b],\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1366'>1367</a>\u001b[0m     [a \u001b[39m+\u001b[39m c \u001b[39m+\u001b[39m b[\u001b[39m0\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m Spelling\u001b[39m.\u001b[39mALPHA]\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1367'>1368</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1368'>1369</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(delete \u001b[39m+\u001b[39m transpose \u001b[39m+\u001b[39m replace \u001b[39m+\u001b[39m insert)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py:1366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1359'>1360</a>\u001b[0m \u001b[39m# Of all spelling errors, 80% is covered by edit distance 1.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1360'>1361</a>\u001b[0m \u001b[39m# Edit distance 1 = one character deleted, swapped, replaced or inserted.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1361'>1362</a>\u001b[0m split \u001b[39m=\u001b[39m [(w[:i], w[i:]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(w) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1362'>1363</a>\u001b[0m delete, transpose, replace, insert \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1363'>1364</a>\u001b[0m     [a \u001b[39m+\u001b[39m b[\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mif\u001b[39;00m b],\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1364'>1365</a>\u001b[0m     [a \u001b[39m+\u001b[39m b[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m b[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m b[\u001b[39m2\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(b) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m],\n\u001b[0;32m-> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1365'>1366</a>\u001b[0m     [a \u001b[39m+\u001b[39;49m c \u001b[39m+\u001b[39;49m b[\u001b[39m1\u001b[39;49m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m Spelling\u001b[39m.\u001b[39mALPHA \u001b[39mif\u001b[39;00m b],\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1366'>1367</a>\u001b[0m     [a \u001b[39m+\u001b[39m c \u001b[39m+\u001b[39m b[\u001b[39m0\u001b[39m:] \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m Spelling\u001b[39m.\u001b[39mALPHA]\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1367'>1368</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/textblob/_text.py?line=1368'>1369</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(delete \u001b[39m+\u001b[39m transpose \u001b[39m+\u001b[39m replace \u001b[39m+\u001b[39m insert)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!pip install textblob\n",
    "def correct_spelling(panda_text_column):\n",
    "    from textblob import TextBlob\n",
    "    return panda_text_column.apply(lambda x: TextBlob(x).correct())\n",
    "\n",
    "df_wikipedia['comment_text'] = correct_spelling(df_wikipedia['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I am ...\n",
       "2    Hey man, I am really not trying to edit war. I...\n",
       "3    \\nMore\\nI cannot make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikipedia['comment_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I am ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I am really not trying to edit war. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\\nMore\\nI cannot make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I am ...      0   \n",
       "2  000113f07ec002fd  Hey man, I am really not trying to edit war. I...      0   \n",
       "3  0001b41b1c6bb37e  \\nMore\\nI cannot make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_URLs_individual(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    return text\n",
    "def process_URLs(panda_text_column):\n",
    "    return panda_text_column.apply(lambda x: process_URLs_individual(x))\n",
    "df_wikipedia['comment_text'] = process_URLs(df_wikipedia['comment_text'])\n",
    "df_wikipedia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate emojis into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dictionary with emojis appearing in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/ylcd0z3n66jgx_wrcv4p13v80000gn/T/ipykernel_88869/3062277311.py:1: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'‚ô•': 'heart suit', '‚ô¶': 'diamond suit', '‚Üî': 'left-right arrow', '‚ô†': 'spade suit', '‚ô£': 'club suit', '‚Ñ¢': 'trade mark', '‚òé': 'telephone', 'üóΩ': 'Statue of Liberty', '¬Æ': 'registered', '¬©': 'copyright'}\n"
     ]
    }
   ],
   "source": [
    "demoji.download_codes()\n",
    "# get dictionary of emojis\n",
    "def get_emojis(panda_text_column):\n",
    "    dict = {}\n",
    "    for row in panda_text_column:\n",
    "        dict.update(demoji.findall(row))\n",
    "    return dict\n",
    "x = get_emojis(df_wikipedia['comment_text'][:1000])\n",
    "print(x)\n",
    "#print(demoji.findall(tweet))\n",
    "#def get_emojis(panda_text_column):\n",
    "#    return panda_text_column.apply(lambda x: demoji.findall(x))\n",
    "#x = get_emojis(df_wikipedia['comment_text'][:1000] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/ylcd0z3n66jgx_wrcv4p13v80000gn/T/ipykernel_75753/621620625.py:3: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/ylcd0z3n66jgx_wrcv4p13v80000gn/T/ipykernel_75753/621620625.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wikipedia['comment_text'][i] = text.replace(item, '')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=12'>13</a>\u001b[0m \u001b[39m#print(demoji.findall(tweet))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=13'>14</a>\u001b[0m \u001b[39m#def get_emojis(panda_text_column):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=14'>15</a>\u001b[0m \u001b[39m#    return panda_text_column.apply(lambda x: demoji.findall(x))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=21'>22</a>\u001b[0m \u001b[39m#                panda_text_column[i] = text.replace(item, '')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=22'>23</a>\u001b[0m \u001b[39m#remove_emojis(df_wikipedia['comment_text'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,text \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(df_wikipedia[\u001b[39m'\u001b[39m\u001b[39mcomment_text\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=24'>25</a>\u001b[0m     dem \u001b[39m=\u001b[39m demoji\u001b[39m.\u001b[39;49mfindall(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m dem:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kw/neuefische/detoxifying-my-social-media/notebooks/preprocessing_kat.ipynb#ch0000040?line=26'>27</a>\u001b[0m         \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m dem\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py:84\u001b[0m, in \u001b[0;36mcache_setter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=80'>81</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=81'>82</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=82'>83</a>\u001b[0m     set_emoji_pattern()\n\u001b[0;32m---> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=83'>84</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py:99\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=88'>89</a>\u001b[0m \u001b[39m@cache_setter\u001b[39m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfindall\u001b[39m(string):\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"Find emojis within ``string``.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=91'>92</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=92'>93</a>\u001b[0m \u001b[39m    :param string: The input text to search\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=95'>96</a>\u001b[0m \u001b[39m    :rtype: dict\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/kw/neuefische/detoxifying-my-social-media/.venv/lib/python3.9/site-packages/demoji/__init__.py?line=98'>99</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {f: _CODE_TO_DESC[f] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(_EMOJI_PAT\u001b[39m.\u001b[39;49mfindall(string))}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def remove_emojis(df, column):\n",
    "    df_copy = df.copy()\n",
    "    for i,text in enumerate(df_copy[column]):\n",
    "        dem = demoji.findall(text)\n",
    "        if dem:\n",
    "            for item in dem.keys():\n",
    "                df_copy[column][i] = text.replace(item, '')\n",
    "    return df_copy\n",
    "\n",
    "remove_emojis(df_wikipedia, 'comment_text')\n",
    "#for i,text in enumerate(df_wikipedia['comment_text']):\n",
    "#    dem = demoji.findall(text)\n",
    "#    if dem:\n",
    "#        for item in dem.keys():\n",
    "#            df_wikipedia['comment_text'][i] = text.replace(item, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Non-Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nontext(panda_column):\n",
    "    return panda_column.apply(lambda x: x.encode(\"utf-8\"))\n",
    "#df_wikipedia[\"comment_text\"] = handle_nontext(df_wikipedia[\"comment_text\"] )\n",
    "#df_wikipedia.tail()\n",
    "\n",
    "# then bytes make it diffcult to deal with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia.to_csv('train_wikipedia_preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad347432433d227a6a1af674451af37b20c66c076ff8f20805b46e8b7d486412"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
