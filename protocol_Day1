<span style="color:grey">

# Day 1, 19.04.2022

## Set Up

### Goals of the Week
* Explore the topic: what has been done before
* Explore the kaggle dataset
* Make baseline model
* EDA
* Fit first NLP models

### Learnings
* <span style="color:grey"> There are two kaggle projects:
    * 2018: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge
    * 2020: http://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification
* About outcome variable: We use "toxic" column. Subclassifications (other columns) only match 95% with toxic classification.
* 10:90 ratio of toxic vs. non toxic comments.
* There are autographic errors.

### Open Questions

</span>
* <span style="color:grey"> Do we need correct autographic mistakes?
* Do we need to balance the data to scale up toxic comments to 50:50?



